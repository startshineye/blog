## hadoop集群配置 

### 集群配置

 ![](./images/3.png)
 hadoop集群分为如上部分：

 * hadoop分为了hdfs跟yarn两部分。
 * hdfs：是分布式文件存储系统，里面的进程包括了3部分；NameNode、DataNode、SecondaryNameNode。DataNode是存储数据的，DataNode数据的索引是存放在NameNode的
   SecondaryNameNode是NameNode元数据的备份。  
 * yarn:是资源调度，里面的进程分为了3部分：ResourceManager、NodeManager、HistoryServer;ResourceManager是一个主进程，用来管理其他进程的；NodeManager是每一个节点上都会存在的，ResourceManager
   只有一个节点上有。HistoryServer用于管理yarn运行的历史记录的。比如上面我们的mapred任务需要执行，他会通过ResourceManager去到NodeManager里面分配资源给mapred运行，执行过成中的记录会被记录在
   HistoryServer中。  



查找对应配置文件

```
# 查找4个核心配置文件：刚开始是空的
find . -name "*.xml" | grep etc | grep -E 'yarn|hdfs-site|mapred|core'
# 查找4个核心配置文件的默认配置文件：其实就是模版
find . -name "*-default.xml" | grep -v rbf
# 分别编辑各配置文件
vim
```

![](./images/4.png)  
 对应的默认配置文件如下:  
![](./images/5.png) 

##### hdfs配置

  进入hadoop的默认根目录下： vim ./etc/hadoop/hdfs-site.xml

```
<configuration>
<property>
 <!--nn web 端访问地址-->
  <name>dfs.namenode.http-address</name>
  <value>0.0.0.0:9870</value>
  <description>
    The address and the base port where the dfs namenode web ui will listen on.
  </description>
</property>
<property>
  <!--2nn web 端访问地址-->
  <name>dfs.namenode.secondary.https-address</name>
  <value>0.0.0.0:9869</value>
  <description>
    The secondary namenode HTTPS server address and port.
  </description>
</property>
</configuration>
```

##### yarn设置

  进入hadoop的默认根目录下： vim ./etc/hadoop/yarn-site.xml

```shell
<configuration>
   <!--指定MR走shuffle-->
   <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <!--指定ResourceManager地址-->
   <property>
        <name>yarn.resourcemanager.hostname</name>
        <!--<value>hadoop162</value>-->
        <value>localhost</value>
    </property>
     <!--环境变量的集成-->
     <property>
    <name>yarn.nodemanager.env-whitelist</name>
<value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ</value>
  </property>
</configuration>
```

##### core设置

  进入hadoop的默认根目录下： vim ./etc/hadoop/core-site.xml

```
<configuration>
<!--指定NameNode的地址-->
<property>
  <name>fs.defaultFS</name>
  <!--<value>hdfs://hadoop161:8020</value>-->
  <value>hdfs://localhost:8020</value>
</property>
<!--指定hadoop数据存储目录-->
<property>
  <name>hadoop.tmp.dir</name>
  <value>/opt/module/hadoop-3.3.1/data</value>
</property>
<!--配置HDFS网页登录使用的静态用户-->
<property>
  <name>hadoop.http.staticuser.user</name>
  <value>root</value>
</property>
</configuration>
```

##### mapreduce配置运行在yarn上
将文件mapred-site.xml.template重命名为mapred-site.xml
添加内容：指定MapReduce运行在YARN上
       
```
<configuration>
<property>
<!--指定MapReduce程序运行在Yarn上-->
  <name>mapreduce.framework.name</name>
  <value>yarn</value>
</property>
</configuration>
```

##### 配置workers

vim ./etc/hadoop/workers 添加如下节点:

```
hadoop161
hadoop162
hadoop163
```

##### 配置hadoop环境变量

  编辑: vim ./etc/hadoop/hadoop-env.sh 

```
export JAVA_HOME=/
```



### 开始初始化和启动

##### 格式化NameNode

格式化NameNode，在NameNode所在的节点161上执行

```
hdfs namenode-format
```

##### 启动hfs

在NameNode所在节点161上执行

```
# 启动跟停止
start-dfs.sh
stop-dfs.sh
```

##### 启动yarn

在ResourceManager所在节点162上执行

```
# 启动 停止
start-yarn.sh
stop-yarn.sh
```



### 服务进程及访问

|          | Hadoop161             | Hadoop162             | Hadoop163             |
| -------- | --------------------- | --------------------- | --------------------- |
| HDFS     | NameNode              |                       | SecondaryNameNode     |
|          | DataNode              | DataNode              | DataNode              |
| YARN     |                       | ResourceManager       |                       |
|          | NodeManager           | NodeManager           | NodeManager           |
| 访问地址 | http://hadoop161:9870 | http://hadoop162:8088 | http://hadoop163:9868 |
|          | http://hadoop161:9864 | http://hadoop162:9864 | http://hadoop163:9864 |

   如上图所示：3台机器的服务进程我们可以通过jps可以看到，我们访问下我们的hdfs可以知道，目前如下:
   
### 附件

1. 启动报错:localhost port 22 Connection refused
```renderscript
启动hadoop进程提示ssh localhost port 22 Connection refused
2021-09-17 17:29  DataBases  阅读(879)  评论(0)  编辑  收藏  举报
hadoop配置完成，用start-all.sh启动时提示错误：
localhost: ssh: connect to host localhost port 22: Connection refused

【错误原因】分析：由于在生产环境下，ssh的端口被修改成9092，不是使用的默认端口，但是hadoop在启动相应进程的时候，使用的ssh默认端口。
【解决问题过程】
1、网上大部分原因是未安装ssh造成的，采用ps -e|grep ssh命令查看，发现服务器上已经安装ssh。
2、ssh localhost，同样提示 Connection refused
3、ssh -p 端口号(9092) localhost，连接成功，发现是端口的问题。
【解决问题办法】
在hadoop-env.sh文件中添加：export HADOOP_SSH_OPTS="-p 端口号(9092)"

https://mp.weixin.qq.com/s/caCk3mM5iXy0FaXCLkDwYQ

https://mp.weixin.qq.com/s/xAvsxEGaCfLCPdVFuJZWPA
```


2. Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).

```renderscript
https://www.jianshu.com/p/bdc9d76da3f1
```

3. Hadoop解决ERROR: namenode can only be executed by root.
```renderscript
https://huaweicloud.csdn.net/63357983d3efff3090b58525.html#:~:text=Hadoop%E8%A7%A3%E5%86%B3ERROR%3A%20namenode%20can%20only%20be%20executed%20by%20root.,HDFS_NAMENODE_USER%3Drootexport%20HDFS_DATANODE_USER%3Drootexport%20HDFS_SECONDARYNAMENODE_USER%3Drootexport%20YARN_RESOURCEMANAGER_USER%3Drootexport%20YARN_NODEMA%20Bonzes%20%C2%B7%E2%80%822021-03-02%2014%3A51%3A39
```






















