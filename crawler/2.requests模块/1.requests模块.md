## 摘要
  主要学习requests这个http模块，该模块主要用于发送请求获取响应，该模块有很多的替代模块，比如说urllib模块，
但是在工作中用的最多的还是requests模块，requests的代码简洁易懂，相对于臃肿的urllib模块，使用requests编写的爬虫代码将会更少，
而且实现某一功能将会简单。因此建议大家掌握该模块的使用。  

知识点：
* 掌握 headers参数的使用
* 掌握 发送带参数的请求
* 掌握 headers中携带cookie
* 掌握 cookies参数的使用
* 掌握 cookieJar的转换方法
* 掌握 超时参数timeout的使用
* 掌握 代理ip参数proxies的使用
* 掌握 使用verify参数忽略CA证书
* 掌握 requests模块发送post请求
* 掌握 利用requests.session进行状态保持

## 内容  

### 1. requests模块介绍
```renderscript
requests文档: http://docs.python-requests.org/zh_CN/latest/index.html

* requests文档:https://requests.readthedocs.io/en/latest/
```

  其中的快速上手跟高级用法需要仔细阅读一遍。爬虫开发中，我们用到的主要是快速上手。高阶用法用的比较少一些。  
  
  

#### 1.1 requests模块的作用
* 发送http请求，获取响应数据。  

#### 1.2 requests模块是一个第三方模块，需要在你的python(虚拟)环境中额外安装

```renderscript
pip/pip3 install requests
```

#### 1.3 requests模块发送get请求
```renderscript
需求：通过requests向百度首页发送请求，获取该页面的源码
运行下面的代码，观察打印输出的结果
```

代码块如下：

```renderscript
# 1.2.1-简单的代码实现
import requests 
# 目标url
url = 'https://www.baidu.com' 
# 向目标url发送get请求
response = requests.get(url)
# 打印响应内容
print(response.text)
```

### 2. response响应对象

```renderscript
* 观察上边代码运行结果发现，有好多乱码；这是因为编解码使用的字符集不同早造成的；我们尝试使用下边的办法来解决中文乱码问题
```

代码如下:
```renderscript
# 1.2.2-response.content
import requests 
# 目标url
url = 'https://www.baidu.com' 
# 向目标url发送get请求
response = requests.get(url)
# 打印响应内容
# print(response.text)
print(response.content.decode()) # 注意这里！
```  

![image](../images/13.png)   

然后我们在响应的时候设置下其对应的编码：
```renderscript
import requests

url = 'https://www.baidu.com'
response = requests.get(url)

print(response.encoding)
response.encoding = 'utf8'
print(response.text)
print(response.encoding)
```

![image](../images/14.png)   

我们设置其响应编码之后，我们发现对应的响应结果为正常显示了。  

1. response.text是requests模块按照chardet模块推测出的编码字符集进行解码的结果
2. 网络传输的字符串都是bytes类型的，所以response.text = response.content.decode('推测出的编码字符集')
3. 我们可以在网页源码中搜索charset，尝试参考该编码字符集，注意存在不准确的情况


#### 2.1 response.text 和response.content的区别
* response.text
  * 类型：str
  * 解码类型： requests模块自动根据HTTP 头部对响应的编码作出有根据的推测，推测的文本编码

* response.content
  * 类型：bytes
  * 解码类型： 没有指定

#### 2.2 通过对response.content进行decode，来解决中文乱码
* response.content.decode() 默认utf-8
* response.content.decode("GBK")
* 常见的编码字符集
  * utf-8
  * gbk
  * gb2312
  * ascii （读音：阿斯克码）
  * iso-8859-1
  
#### 2.3 response响应对象的其它常用属性或方法
```renderscript
response = requests.get(url)中response是发送请求获取的响应对象；
response响应对象中除了text、content获取响应内容以外还有其它常用的属性或方法：
```  

* response.url响应的url；有时候响应的url和请求的url并不一致
* response.status_code 响应状态码
* response.request.headers 响应对应的请求头
* response.headers 响应头
* response.request._cookies 响应对应请求的cookie；返回cookieJar类型
* response.cookies 响应的cookie（经过了set-cookie动作；返回cookieJar类型
* response.json()自动将json字符串类型的响应内容转换为python对象（dict or list）

知识点：掌握 response响应对象的其它常用属性。

### 3. requests模块发送请求
#### 3.1 发送带header的请求
###### 爬虫获取数据大小
  首先，我们使用如下代码:
  
```renderscript
import requests

url = 'https://www.baidu.com'
response = requests.get(url)

# 第一种模式
print(len(response.content.decode()))
```

程序输出的结果为:2349  

```renderscript
<!DOCTYPE html>
<!--STATUS OK--><html> <head><meta http-equiv=content-type content=text/html;charset=utf-8><meta http-equiv=X-UA-Compatible content=IE=Edge><meta content=always name=referrer><link rel=stylesheet type=text/css href=https://ss1.bdstatic.com/5eN1bjq8AAUYm2zgoY3K/r/www/cache/bdorz/baidu.min.css><title>百度一下，你就知道</title></head> <body link=#0000cc> <div id=wrapper> <div id=head> <div class=head_wrapper> <div class=s_form> <div class=s_form_wrapper> <div id=lg> <img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129> </div> <form id=form name=f action=//www.baidu.com/s class=fm> <input type=hidden name=bdorz_come value=1> <input type=hidden name=ie value=utf-8> <input type=hidden name=f value=8> <input type=hidden name=rsv_bp value=1> <input type=hidden name=rsv_idx value=1> <input type=hidden name=tn value=baidu><span class="bg s_ipt_wr"><input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus=autofocus></span><span class="bg s_btn_wr"><input type=submit id=su value=百度一下 class="bg s_btn" autofocus></span> </form> </div> </div> <div id=u1> <a href=http://news.baidu.com name=tj_trnews class=mnav>新闻</a> <a href=https://www.hao123.com name=tj_trhao123 class=mnav>hao123</a> <a href=http://map.baidu.com name=tj_trmap class=mnav>地图</a> <a href=http://v.baidu.com name=tj_trvideo class=mnav>视频</a> <a href=http://tieba.baidu.com name=tj_trtieba class=mnav>贴吧</a> <noscript> <a href=http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb>登录</a> </noscript> <script>document.write('<a href="http://www.baidu.com/bdorz/login.gif?login&tpl=mn&u='+ encodeURIComponent(window.location.href+ (window.location.search === "" ? "?" : "&")+ "bdorz_come=1")+ '" name="tj_login" class="lb">登录</a>');
                </script> <a href=//www.baidu.com/more/ name=tj_briicon class=bri style="display: block;">更多产品</a> </div> </div> </div> <div id=ftCon> <div id=ftConw> <p id=lh> <a href=http://home.baidu.com>关于百度</a> <a href=http://ir.baidu.com>About Baidu</a> </p> <p id=cp>&copy;2017&nbsp;Baidu&nbsp;<a href=http://www.baidu.com/duty/>使用百度前必读</a>&nbsp; <a href=http://jianyi.baidu.com/ class=cp-feedback>意见反馈</a>&nbsp;京ICP证030173号&nbsp; <img src=//www.baidu.com/img/gs.gif> </p> </div> </div> </div> </body> </html>

```

###### 网页获取数据大小  
![image](../images/15.png)  
  发现大小为大于5000;发现其响应的结果除了上面的代码之外，还出现了css等样式。
这里面的区别到底在哪里？你不是模拟的浏览器吗？在发送请求的时候，我们可以预先设置一些请求头模拟浏览器。我们可以看到我们的浏览器请求baidu的时候带上
我们之前说的三大剑客：User-Agent、Referer、Cookie即可。  
由于目前我们访问baidu的时候是不需要用户保持的，所以是不需要使用cookie的。并且我们也没有从哪里来的情况，所以我们只需要
使用:User-Agent。

```renderscript
import requests
url = 'https://www.baidu.com'
# 构建请求头字典
headers = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36"
}

# 发送请求
res = requests.get(url, headers=headers)
print(res.content.decode())
print(len(res.content.decode()))
```

上面输出的结果就是:365023;
上面就是告诉浏览器，我们使用了浏览器的代理了。  

##### 3.1.1 思考
![image](../images/16.png)  

##### 3.1.2 携带请求头发送请求的方法
```renderscript
requests.get(url, headers=headers)
```

* headers参数接收字典形式的请求头
* 请求头字段名作为key，字段对应的值作为value

#### 3.2 发送带参数的请求
```renderscript
我们在使用百度搜索的时候经常发现url地址中会有一个 ?，那么该问号后边的就是请求参数，又叫做查询字符串.
```







