## 摘要
基本的目录结构如下：  
`决策树`   
* 决策树介绍
* 三种特征选择准则  
* 决策树生成算法  
* 处理连续值方法
* 处理回归问题方法  
* 决策树剪枝  
* 决策树小结  

`随机森林`  
* 随机森林介绍  
* 提高随机森林中决策树Diversity的方法  
* Ensemble methods  
* Bagging vs. Boosting  

## 内容

### 1.决策树
#### 1.1 决策树简介
  我们介绍决策树，主要是最终目的是boosting算法 跟GBDT算法。其是在深度学习中非常流行的算法。  
决策树是一个比较常见的机器学习方法。 能处理我们分类跟回归的问题。 
![](../images/42.png)  

  上面是我们现实生活中常见的例子:比如我们去看病的时候,有些医生会根据我们发烧程度去判断我们
病因，比如被判断为肌肉疼痛、然后给出一些处方。
  第二个医生的话，首先可能会根据我们肌肉疼痛角度去判断发烧，然后再去开处方。

#### 1.2 决策树构成  
  决策树由节点和边构成。
![](../images/43.png)   
  以上
     红色--代表根节点。
     蓝色--代表内部节点
     绿色--代表叶子节点
  之间节点之间的连线代表边
 

#### 1.3 决策树与对应的决策边界  
![](../images/44.png)  
上面是决策树与其对应的决策边界。左边决策树中涉及到的特征是:x1,x2；是一个两维的特征；所以其对应的
决策边界是一个平面；通过θ1,θ4将横轴切分成了多个等份。 树往下扩展的话，其叶子节点越来越多，并且对应的
决策边界划分的就越来越仔细。  
  
#### 1.4 决策树学习内容
   需要学习的三个内容:  
* 树的形状  
* 每个决策的阈值θi  
* 叶节点的值  

![](../images/45.png)  

#### 1.5 例子  
  基于给定数据如何构造一个决策树。  
![](../images/46.png)  
 如上图：我们的数据样本就是10个；
 左边图：  
   前两列代表的是我们的输入(1、工作年限小于2年 2、信用卡没有按时还过)  第3列代表的是output；代表的是是否逾期。  
  
根据左边的图，我们可以构造一颗决策树，其对应的样子 如右图所示：
将"工作年限小于2年"作为跟节点，然后"信用卡没有按时还过"作为内部节点，
